# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ohdGYvE6MEgTfKr26dLuzJ88nWWimszH
"""

# app.py
import streamlit as st
import pandas as pd
import numpy as np
import pickle
from sklearn.datasets import load_iris

# Load model
with open('random_forest_model.pkl', 'rb') as f:
    model = pickle.load(f)

# Load dataset
iris = load_iris()
iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)
iris_df['species'] = pd.Categorical.from_codes(iris.target, iris.target_names)

# Sidebar navigation
st.sidebar.title("Iris Classifier App")
page = st.sidebar.radio("Go to", ["Data Description", "Predict Iris", "Model Info"])

# Page 1: Data Description
if page == "Data Description":
    st.title("üìä Iris Dataset Description")
    st.write("""
        The Iris dataset contains 150 samples of iris flowers from three species:
        * Setosa
        * Versicolor
        * Virginica
    """)
    st.dataframe(iris_df.head())

    st.subheader("Class Distribution")
    st.bar_chart(iris_df['species'].value_counts())

    st.subheader("Feature Overview")
    st.line_chart(iris_df.drop(columns='species'))

# Page 2: Predict Iris
elif page == "Predict Iris":
    st.title("üîç Predict Iris Species")

    st.write("Enter the flower measurements:")
    sepal_length = st.slider("Sepal Length (cm)", 4.0, 8.0, 5.1)
    sepal_width = st.slider("Sepal Width (cm)", 2.0, 4.5, 3.5)
    petal_length = st.slider("Petal Length (cm)", 1.0, 7.0, 1.4)
    petal_width = st.slider("Petal Width (cm)", 0.1, 2.5, 0.2)

    if st.button("Predict"):
        features = np.array([[sepal_length, sepal_width, petal_length, petal_width]])
        prediction = model.predict(features)[0]
        species = iris.target_names[prediction]
        st.success(f"The predicted species is **{species}**")

# Page 3: Model Info
elif page == "Model Info":
    st.title("üß† About the Naive Bayes Model")
    st.write("""
        Naive Bayes is a probabilistic classifier based on Bayes‚Äô theorem.
        It assumes that features are independent given the class label.

        **Advantages:**
        - Simple and fast
        - Works well with small datasets
        - Performs well on multiclass problems

        **Formula:**
        \\[
        P(C|X) = \\frac{P(X|C)P(C)}{P(X)}
        \\]

        This app uses a **Gaussian Naive Bayes** model since our features are continuous.
    """)
